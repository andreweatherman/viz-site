{
  "hash": "caaa4942bd6658d40bceac5329a844ba",
  "result": {
    "markdown": "---\ntitle: \"An Infinite Number of Monkeys\"\ndate: \"2023-02-24\"\ncategories: [R, web scraping, quantile regression, linear regression, rolling join, special effects]\ndescription: \"Quantile regression, property sales and anything could happen eventually\"\nbibliography: references.bib\n---\n\n\n![](feature.jpg){fig-alt=\"A monkey with badge number 15 sits at a typewriter and types: 'To be. Or not to be. That is the gazornanplatt.'\"}\n\nMore on the monkeys later.\n\nFor now, the focus is on modelled house sales in London SW10 using quantile (and linear) regression. Several other \"little projects\" have looked at these residential properties from other perspectives:\n\n-   [House Sales](/project/sw10/) and the impact of historical events.\n\n-   [Digging Deep](/project/planning) and the correlation between sales and planning applications.\n\n-   [Bootstraps & Bandings](/project/bands) and inferring whether property bands are as representative of property values today as they were three decades ago.\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(xts.warn_dplyr_breaks_lag = FALSE)\n\nlibrary(conflicted)\nlibrary(tidyverse)\nconflict_prefer_all(\"dplyr\", quiet = TRUE)\nconflicts_prefer(purrr::map)\nconflict_prefer(\"as_date\", \"lubridate\")\nlibrary(scales)\nlibrary(glue)\nlibrary(SPARQL)\nlibrary(paletteer)\nlibrary(tsibble)\nlibrary(rvest)\nlibrary(Quandl)\nlibrary(corrr)\nlibrary(quantreg)\nlibrary(Qtools)\nlibrary(ggfx)\nlibrary(usedthese)\n\nconflict_scout()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntheme_set(theme_bw())\n\nn <- 4\npalette <- \"wesanderson::Royal1\"\n\ncols <- paletteer_d(palette, n = n)\n\ntibble(x = 1:n, y = 1) |>\n  ggplot(aes(x, y, fill = cols)) +\n  geom_col(colour = \"white\") +\n  geom_label(aes(label = cols |> str_remove(\"FF$\")), \n             size = 4, vjust = 2, fill = \"white\") +\n  annotate(\n    \"label\",\n    x = (n + 1) / 2, y = 0.5,\n    label = palette,\n    fill = \"white\",\n    alpha = 0.8,\n    size = 6\n  ) +\n  scale_fill_manual(values = as.character(cols)) +\n  theme_void() +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/theme-1.png){width=100%}\n:::\n:::\n\n\nHouse transaction data are provided by [HM Land Registry Open Data](http://landregistry.data.gov.uk/app/qonsole#).\n\n\n::: {.cell hash='index_cache/html/land registry_5b8b4c7c811ffac13e67aba65b66961f'}\n\n```{.r .cell-code}\nendpoint <- \"https://landregistry.data.gov.uk/landregistry/query\"\n\nquery <- 'PREFIX  text: <http://jena.apache.org/text#>\nPREFIX  ppd:  <http://landregistry.data.gov.uk/def/ppi/>\nPREFIX  lrcommon: <http://landregistry.data.gov.uk/def/common/>\n  \nSELECT  ?item ?ppd_propertyAddress ?ppd_hasTransaction ?ppd_pricePaid ?ppd_transactionCategory ?ppd_transactionDate ?ppd_transactionId ?ppd_estateType ?ppd_newBuild ?ppd_propertyAddressCounty ?ppd_propertyAddressDistrict ?ppd_propertyAddressLocality ?ppd_propertyAddressPaon ?ppd_propertyAddressPostcode ?ppd_propertyAddressSaon ?ppd_propertyAddressStreet ?ppd_propertyAddressTown ?ppd_propertyType ?ppd_recordStatus\n\nWHERE\n{ ?ppd_propertyAddress text:query _:b0 .\n  _:b0 <http://www.w3.org/1999/02/22-rdf-syntax-ns#first> lrcommon:postcode .\n  _:b0 <http://www.w3.org/1999/02/22-rdf-syntax-ns#rest> _:b1 .\n  _:b1 <http://www.w3.org/1999/02/22-rdf-syntax-ns#first> \"( SW10 )\" .\n  _:b1 <http://www.w3.org/1999/02/22-rdf-syntax-ns#rest> _:b2 .\n  _:b2 <http://www.w3.org/1999/02/22-rdf-syntax-ns#first> 3000000 .\n  _:b2 <http://www.w3.org/1999/02/22-rdf-syntax-ns#rest> <http://www.w3.org/1999/02/22-rdf-syntax-ns#nil> .\n  ?item ppd:propertyAddress ?ppd_propertyAddress .\n  ?item ppd:hasTransaction ?ppd_hasTransaction .\n  ?item ppd:pricePaid ?ppd_pricePaid .\n  ?item ppd:transactionCategory ?ppd_transactionCategory .\n  ?item ppd:transactionDate ?ppd_transactionDate .\n  ?item ppd:transactionId ?ppd_transactionId\n  \n  OPTIONAL { ?item ppd:estateType ?ppd_estateType }\n  OPTIONAL { ?item ppd:newBuild ?ppd_newBuild }\n  OPTIONAL { ?ppd_propertyAddress lrcommon:county ?ppd_propertyAddressCounty }\n  OPTIONAL { ?ppd_propertyAddress lrcommon:district ?ppd_propertyAddressDistrict }\n  OPTIONAL { ?ppd_propertyAddress lrcommon:locality ?ppd_propertyAddressLocality }\n  OPTIONAL { ?ppd_propertyAddress lrcommon:paon ?ppd_propertyAddressPaon }\n  OPTIONAL { ?ppd_propertyAddress lrcommon:postcode ?ppd_propertyAddressPostcode }\n  OPTIONAL { ?ppd_propertyAddress lrcommon:saon ?ppd_propertyAddressSaon }\n  OPTIONAL { ?ppd_propertyAddress lrcommon:street ?ppd_propertyAddressStreet }\n  OPTIONAL { ?ppd_propertyAddress lrcommon:town ?ppd_propertyAddressTown }\n  OPTIONAL { ?item ppd:propertyType ?ppd_propertyType }\n  OPTIONAL { ?item ppd:recordStatus ?ppd_recordStatus }\n}'\n\ndata_lst <- SPARQL(endpoint, query)\n```\n:::\n\n\nI intend to model the data by year-month and project two months beyond the last recorded actuals.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_df <- data_lst |>\n  pluck(\"results\") |>\n  as_tibble() |>\n  mutate(\n    date = as_datetime(ppd_transactionDate) |> as_date(),\n    amount = ppd_pricePaid,\n    cat = str_remove(ppd_transactionCategory, \n                     \"<http://landregistry.data.gov.uk/def/ppi/\"),\n  ) |>\n  filter(str_detect(cat, \"standard\")) |>\n  arrange(date) |>\n  mutate(yr_mon = yearmonth(date)) |>\n  count(yr_mon)\n\nnext_month <- data_df |>\n  summarise(last(yr_mon) + 1) |>\n  pull()\n\n# Add two months for predictions\ndata_df2 <- data_df |>\n  rows_insert(tibble(yr_mon = next_month), by = \"yr_mon\") |>\n  rows_insert(tibble(yr_mon = next_month + 1), by = \"yr_mon\")\n```\n:::\n\n\nThere are various sources available for macroeconomic factors that may affect house sales activity. Inflation and interest rates (the latter impacting mortgage rates) could be influential. SW10 has many overseas buyers, so the effective exchange rate versus a basket of currencies could too be a useful predictor.\n\nI'll use the Quandl [@Quandl] R package to grab most of these.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Price of a selection of goods & services for a typical consumer\ncpi_df <- Quandl(\"RATEINF/CPI_GBR\") |>\n  select(date = Date, cpi_macro = Value) |>\n  arrange(date) |>\n  mutate(yr_mon = yearmonth(date)) |>\n  select(-date)\n\n# YOY rate of change in CPI\ninflation_df <- Quandl(\"RATEINF/INFLATION_GBR\") |>\n  select(date = Date, inflation_macro = Value) |>\n  arrange(date) |>\n  mutate(yr_mon = yearmonth(date)) |>\n  select(-date)\n\n# BOE base rate\ninterest_df <-\n  read_html(\"https://www.bankofengland.co.uk/boeapps/database/Bank-Rate.asp\") |>\n  html_elements(\"#stats-table\") |>\n  html_table() |>\n  pluck(1) |>\n  mutate(date = dmy(`Date Changed`)) |>\n  select(date, interest_macro = Rate) |>\n  arrange(date) |>\n  mutate(yr_mon = yearmonth(date)) |>\n  select(-date) |>\n  slice_tail(n = 1, by = yr_mon)\n\n# Effective exchange rate of sterling versus multiple other currencies\nsterling_df <- Quandl(\"BOE/XUDLBK67\") |>\n  select(date = Date, sterling_macro = Value) |>\n  arrange(date) |>\n  mutate(yr_mon = yearmonth(date)) |>\n  slice_tail(n = 1, by = yr_mon) |>\n  select(-date)\n\nmacro_list <-\n  list(\n    inflation_df,\n    cpi_df,\n    interest_df,\n    sterling_df\n  )\n\nmacro_df <- reduce(macro_list, left_join, join_by(yr_mon)) |>\n  arrange(yr_mon) |>\n  fill(ends_with(\"macro\"), .direction = \"down\") |>\n  drop_na()\n\nmacro_df |>\n  pivot_longer(-yr_mon) |>\n  mutate(name = str_remove(name, \"_macro\")) |>\n  ggplot(aes(yr_mon, value)) +\n  geom_line(colour = \"grey70\") +\n  geom_smooth() +\n  facet_wrap(~name, scales = \"free_y\", nrow = 1) +\n  labs(title = \"Macroeconomic Factors\", x = NULL) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/macro economic-1.png){width=100%}\n:::\n:::\n\n\nThe UK government imposes a stamp duty on house buyers as a percentage of the sale price, so changes in the rate, particularly the top rate, could be a helpful input to the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstamp_df <- read_html(\"https://www.investmentguide.co.uk/historical-stamp-duty/\") |>\n  html_elements(\"strong , .column-1, .column-2\") |>\n  html_text() |>\n  as_tibble() |>\n  filter(!value %in% c(\"Rate\", \"Charge band\")) |>\n  mutate(type = case_when(\n    str_detect(value, \"%\") ~ \"rate\",\n    str_detect(value, \"Â£\") ~ \"band\",\n    .default = \"date\"\n  )) |>\n  mutate(yr_mon = if_else(type == \"date\", yearmonth(dmy(value)), NA)) |>\n  fill(yr_mon) |>\n  filter(type != \"date\") |>\n  mutate(row = row_number(), .by = c(yr_mon, type)) |>\n  pivot_wider(names_from = type, values_from = value) |>\n  separate_wider_delim(band, \" and under \",\n    names = c(\"from\", \"to\"), too_few = \"align_start\"\n  ) |>\n  mutate(\n    to = if_else(str_starts(from, \"Up to\"), parse_number(from), parse_number(to)),\n    to = replace_na(to, Inf)\n  ) |>\n  select(-from)\n\nstamp_df2 <- stamp_df |>\n  filter(to == Inf) |>\n  select(yr_mon, stamp_macro = rate) |>\n  mutate(stamp_macro = parse_number(stamp_macro))\n\n# saveRDS(stamp_df, \"stamp_df\")\n```\n:::\n\n\nScatter plots and correlations suggest these could be worth incorporating.\n\nA further refinement would be to try the correlations at various lags to see where the relationship is strongest. This is because it often takes weeks from decision-to-sell to completion. On the other hand one can often get a broad sense of the direction of some of these factors ahead of time.\n\nMonths are included as, for example, there are typically weaker sales in winter.\n\n\n::: {.cell}\n\n```{.r .cell-code}\njoin_df <- data_df2 |>\n  left_join(macro_df, join_by(yr_mon == yr_mon)) |>\n  left_join(stamp_df2, join_by(closest(yr_mon >= yr_mon))) |>\n  select(-starts_with(\"date\"), -yr_mon.y) |>\n  mutate(across(ends_with(\"_macro\"), lag, 2)) |>\n  drop_na(-n) |>\n  rename(yr_mon = yr_mon.x) |>\n  mutate(month = month(yr_mon))\n\njoin_df |> \n  mutate(month = month(yr_mon, label = TRUE)) |> \n  ggplot(aes(month, n, group = month)) +\n  geom_boxplot() +\n  labs(title = \"Sales by Month\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/correlation-1.png){width=100%}\n:::\n\n```{.r .cell-code}\njoin_df |>\n  select(-month) |>\n  correlate() |>\n  focus(n) |>\n  arrange(n)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|term            |          n|\n|:---------------|----------:|\n|cpi_macro       | -0.6455062|\n|stamp_macro     | -0.6009742|\n|inflation_macro | -0.2273802|\n|sterling_macro  |  0.5551985|\n|interest_macro  |  0.5702645|\n\n</div>\n:::\n\n```{.r .cell-code}\njoin_df |>\n  pivot_longer(cols = ends_with(\"_macro\"), names_pattern = \"(.*)_macro\") |>\n  ggplot(aes(value, n)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(~name, scales = \"free_x\", nrow = 1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/correlation-2.png){width=100%}\n:::\n:::\n\n\nThe quantreg [@quantreg] R package is used here to model the 0.5 (median), 0.05 and 0.95 quantiles, Qtools [@Qtools] to extract the goodness-of-fit and broom [@broom] to tidy the term estimates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\n\nrq_fit <- rq(\n  n ~ cpi_macro + sterling_macro + interest_macro +\n    stamp_macro + inflation_macro + month + yr_mon,\n  data = join_df,\n  tau = c(0.05, 0.5, 0.95)\n)\n\nbroom::tidy(rq_fit)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|term            |    estimate|     conf.low|  conf.high|  tau|\n|:---------------|-----------:|------------:|----------:|----:|\n|(Intercept)     |  17.4009501|  -14.7567771| 59.4204115| 0.05|\n|cpi_macro       |   1.2033609|    0.5643921|  2.0407098| 0.05|\n|sterling_macro  |   0.5006562|    0.0987317|  0.6939156| 0.05|\n|interest_macro  |  -2.7824965|   -5.7330986|  0.9568033| 0.05|\n|stamp_macro     |  -0.8282729|   -2.0024868|  0.6587759| 0.05|\n|inflation_macro |  -0.6752318|   -3.3044990|  1.1818529| 0.05|\n|month           |   0.0937169|   -0.3222418|  0.9383533| 0.05|\n|yr_mon          |  -0.0095708|   -0.0162135| -0.0069172| 0.05|\n|(Intercept)     | -21.3647250|  -54.1113789| 22.7165990| 0.50|\n|cpi_macro       |   1.0272546|    0.3906825|  1.6199574| 0.50|\n|sterling_macro  |   0.7949216|    0.5864052|  1.0089153| 0.50|\n|interest_macro  |  -1.2533022|   -2.8965037|  0.3466491| 0.50|\n|stamp_macro     |  -1.4047908|   -2.5197048| -0.2199744| 0.50|\n|inflation_macro |  -0.9364530|   -1.8156209|  0.7039052| 0.50|\n|month           |  -0.0556925|   -0.3636425|  0.3755751| 0.50|\n|yr_mon          |  -0.0064439|   -0.0101636| -0.0041408| 0.50|\n|(Intercept)     | -15.3193185| -206.2506214| 66.5261549| 0.95|\n|cpi_macro       |   1.6141478|    0.0050755|  4.9586657| 0.95|\n|sterling_macro  |   0.8385557|   -0.1130984|  1.7694980| 0.95|\n|interest_macro  |  -0.4391986|   -4.6575196|  5.9785501| 0.95|\n|stamp_macro     |  -1.0817821|   -6.1706778|  4.0196441| 0.95|\n|inflation_macro |  -2.6217660|   -8.0469028|  1.6613280| 0.95|\n|month           |   0.0435900|   -1.3331433|  1.6996293| 0.95|\n|yr_mon          |  -0.0095591|   -0.0228147|  0.0044122| 0.95|\n\n</div>\n:::\n\n```{.r .cell-code}\nGOFTest(rq_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGoodness-of-fit test for quantile regression based on the cusum process \nA large test statistic (small p-value) is evidence of lack of fit \nQuantile 0.05: Test statistic = 7e-04; p-value = 0.62 \nQuantile 0.5: Test statistic = 0.0061; p-value = 0.23 \nQuantile 0.95: Test statistic = 0.001; p-value = 0.53 \n```\n:::\n\n```{.r .cell-code}\nlm_fit <- rq(\n  n ~ cpi_macro + sterling_macro + interest_macro +\n    stamp_macro + inflation_macro + month + yr_mon,\n  data = join_df\n)\n\nrq_preds <- rq_fit |>\n  predict(join_df,\n    type = \"quantiles\",\n    quantiles = c(0.05, 0.5, 0.95)\n  ) |>\n  as_tibble() |>\n  rename(\n    lower = `tau= 0.05`,\n    median = `tau= 0.50`,\n    upper = `tau= 0.95`\n  ) |>\n  bind_cols(join_df) |>\n  mutate(coverage = if_else(between(n, lower, upper), TRUE, FALSE))\n\nlm_preds <- lm_fit |>\n  predict(join_df) |>\n  as_tibble() |>\n  bind_cols(join_df) |>\n  select(yr_mon, lm = value)\n```\n:::\n\n\nThe goodness-of-fit seems reasonable, so let's visualise the quantile and linear regressions along with the actual sales for comparison.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoverage <- rq_preds |> \n  summarise(coverage = percent(mean(coverage, na.rm = TRUE), 0.1)) |> \n  pull()\n\nrq_preds |>\n  left_join(lm_preds, join_by(yr_mon == yr_mon)) |>\n  ggplot(aes(yr_mon, median)) +\n  as_reference(geom_ribbon(aes(ymin = lower, ymax = upper), \n                           fill = cols[1]), id = \"ribbon\") +\n  with_blend(\n    annotate(\n      \"rect\",\n      xmin = ymd(\"2022-12-31\"), xmax = ymd(\"2023-02-28\"),\n      ymin = -Inf, ymax = Inf, fill = cols[2], linetype = \"dashed\"\n    ),\n    bg_layer = \"ribbon\", blend_type = \"atop\"\n  ) +\n  geom_line(aes(y = n), colour = \"black\") +\n  geom_line(colour = \"white\", linewidth = 1) +\n  geom_line(aes(y = lm), colour = cols[4], linetype = \"dashed\") +\n  geom_vline(xintercept = ymd(\"2008-09-06\"), \n             linetype = \"dashed\", colour = \"grey30\") +\n  annotate(\"label\",\n    x = yearmonth(\"2008 Sep\"), y = 100,\n    label = \"Lehman\\nBrothers\\nCollapses\", size = 3\n  ) +\n  geom_vline(xintercept = ymd(\"2014-12-03\"), \n             linetype = \"dashed\", colour = \"grey30\") +\n  annotate(\"label\",\n    x = yearmonth(\"2014 Dec\"), y = 100,\n    label = \"Jump in\\nTop-rate\\nStamp\\nDuty\", size = 3\n  ) +\n  geom_vline(xintercept = ymd(\"2016-06-23\"), \n             linetype = \"dashed\", colour = \"grey30\") +\n  annotate(\"label\",\n    x = yearmonth(\"2016 Jun\"), y = 65,\n    label = \"Brexit\\nVote\", size = 3\n  ) +\n  annotate(\"label\",\n    x = yearmonth(\"2020 Jun\"), y = 120,\n    label = glue(\n      \"Actual (Black)\\nLinear (Dashed Orange)\\n\",\n      \"Quantiles (Grey / White)\\nPredicted (Red / White)\"\n    ),\n    size = 3\n  ) +\n  annotate(\"label\",\n    x = yearmonth(\"1999 Jan\"), y = 125,\n    label = glue(\"{coverage} Coverage\"), \n    size = 3, fill = cols[1], colour = \"white\"\n  ) +\n  scale_x_yearmonth(date_breaks = \"2 years\") +\n  labs(\n    title = \"Monthly House Sales in London Postcode Area SW10\",\n    subtitle = \"Quantile (0.05, 0.5, 0.95) & Linear Regression\",\n    x = NULL, y = \"Number of Sales\", fill = NULL\n  ) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot-1.png){width=100%}\n:::\n:::\n\n\nThe 90% prediction interval (0.05 to 0.95 quantiles represented by the grey ribbon) covers 89.2% of the historical observations and suggests a 95% probability of no more than 26 sales in February.\n\nOf course that means there is a one-in-twenty chance of more, and an even smaller chance of repeating the summer of 2003. Anything can happen eventually.\n\nAs Bob Newhart pointed out, an infinite number of monkeys given enough time, could one day type out all the great books! A wide prediction interval though would suggest gibberish. So, you might want to busy yourself with other things in the meantime.\n\n\n{{< video https://www.youtube.com/watch?v=Ngmf8G5xKas >}}\n\n\n\n## R Toolbox\n\nSummarising below the packages and functions used in this post enables me to separately create a [toolbox visualisation](/project/box) summarising the usage of packages and functions across all posts.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nused_here()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"usedthese table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Package </th>\n   <th style=\"text-align:left;\"> Function </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Qtools </td>\n   <td style=\"text-align:left;\"> GOFTest[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Quandl </td>\n   <td style=\"text-align:left;\"> Quandl[3] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> SPARQL </td>\n   <td style=\"text-align:left;\"> SPARQL[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> base </td>\n   <td style=\"text-align:left;\"> as.character[1], c[5], library[14], list[1], mean[1], options[1], set.seed[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> broom </td>\n   <td style=\"text-align:left;\"> tidy[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> conflicted </td>\n   <td style=\"text-align:left;\"> conflict_prefer[1], conflict_prefer_all[1], conflict_scout[1], conflicts_prefer[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> corrr </td>\n   <td style=\"text-align:left;\"> correlate[1], focus[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> dplyr </td>\n   <td style=\"text-align:left;\"> across[1], arrange[7], between[1], bind_cols[2], case_when[1], count[1], filter[4], if_else[3], join_by[4], last[1], left_join[3], mutate[17], pull[2], rename[2], row_number[1], rows_insert[2], select[13], slice_tail[2], summarise[2] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ggfx </td>\n   <td style=\"text-align:left;\"> as_reference[1], with_blend[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ggplot2 </td>\n   <td style=\"text-align:left;\"> aes[9], annotate[7], element_text[2], facet_wrap[2], geom_boxplot[1], geom_col[1], geom_label[1], geom_line[4], geom_point[1], geom_ribbon[1], geom_smooth[2], geom_vline[3], ggplot[5], labs[3], scale_fill_manual[1], theme[3], theme_bw[1], theme_set[1], theme_void[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> glue </td>\n   <td style=\"text-align:left;\"> glue[2] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lubridate </td>\n   <td style=\"text-align:left;\"> as_date[1], as_datetime[1], dmy[2], month[2], ymd[5] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> paletteer </td>\n   <td style=\"text-align:left;\"> paletteer_d[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> purrr </td>\n   <td style=\"text-align:left;\"> pluck[2], reduce[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> quantreg </td>\n   <td style=\"text-align:left;\"> rq[2] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> readr </td>\n   <td style=\"text-align:left;\"> parse_number[3] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rvest </td>\n   <td style=\"text-align:left;\"> html_elements[2], html_table[1], html_text[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> scales </td>\n   <td style=\"text-align:left;\"> percent[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> stats </td>\n   <td style=\"text-align:left;\"> predict[2] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> stringr </td>\n   <td style=\"text-align:left;\"> str_detect[3], str_remove[3], str_starts[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> tibble </td>\n   <td style=\"text-align:left;\"> as_tibble[4], tibble[3] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> tidyr </td>\n   <td style=\"text-align:left;\"> drop_na[2], fill[2], pivot_longer[2], pivot_wider[1], replace_na[1], separate_wider_delim[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> tidyselect </td>\n   <td style=\"text-align:left;\"> ends_with[3], starts_with[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> tsibble </td>\n   <td style=\"text-align:left;\"> scale_x_yearmonth[1], yearmonth[11] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> usedthese </td>\n   <td style=\"text-align:left;\"> used_here[1] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> xml2 </td>\n   <td style=\"text-align:left;\"> read_html[2] </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}