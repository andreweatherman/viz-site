{
  "hash": "1ffe5476f6a0908584c0b3e092bcf0b4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Polls: SportsRef\"\nauthor: \"Andrew Weatherman\"\ndate: \"2024-05-18\"\ncategories: [college basketball, scraping, tutorial, sports reference]\ndescription: \"Using `rvest` to scrape AP and Coaches polls from Sports Reference\"\n---\n\n\n## Introduction\n\nOne of the easiest places to scrape current and historical poll data from is Sports Reference.\n\n::: {.callout-warning}\nSports Reference limits users to 20 requests per minute, so to avoid an HTTP 429 error (\"too many requests\"), all functions must use a sleep of three or more seconds -- `Sys.sleep(3)`.\n:::\n\nFor this template, you need the following packages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\nlibrary(tidyverse)\nlibrary(janitor)\n```\n:::\n\n\n## Structure\n\nSports Reference segments data by season, meaning that you need to loop over a vector of years to grab all data. For Associated Press polls (\"AP Poll\"), that data is found at the following link: `…/{men/women}/{season}-polls.html`. For the USA Today Coaches Poll, that is found at: `…/{men/women}/{season}-polls-coaches.html`. Like all data on Sports Reference, things are displayed using *static* HTML tables, meaning that `rvest` can be used.\n\n## Functions\n\nThe functions below are written to pull *men's* data. If you want women's polling data, simply change \"men\" to \"women\" in each URL.\n\n### AP Poll\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_ap_poll <- function(year) {\n  \n  url <- paste0('https://www.sports-reference.com/cbb/seasons/men/', year, '-polls.html')\n  \n  Sys.sleep(3)\n  \n  html <- read_html(url)\n  \n  # for current poll // past years will not have a 'current' poll so we need to catch that error\n  current_poll <- tryCatch({\n    html %>%\n      html_nodes(\"#current-poll\") %>%\n      html_table() %>% \n      pluck(1) %>% \n      clean_names() %>% \n      mutate(chng = as.numeric(chng),\n             year = year)\n  }, error = function(e) {NULL})\n    \n  # for season-long polls\n  all_polls <- html %>%\n    html_nodes(\"#ap-polls\") %>%\n    html_table() %>% \n    pluck(1) %>% \n    row_to_names(2) %>% \n    clean_names() %>% \n    rename_with(~paste0(\"week_\", seq_along(.)), starts_with(\"x\")) %>% # shift to week_X name format\n    mutate(across(-c(school, conf), as.numeric),\n           year = year)\n  \n  return(list(\"current\" = current_poll, \"all\" = all_polls))\n\n}\n```\n:::\n\n\n### Coaches Poll\n\nThe coded necessary to scrape the Coaches Poll is analogous to that of the AP function but we switch the URL.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_coaches_poll <- function(year) {\n  \n  url <- paste0('https://www.sports-reference.com/cbb/seasons/men/', year, '-polls-coaches.html')\n  \n  Sys.sleep(3)\n  \n  html <- read_html(url)\n  \n  # for current poll // past years will not have a 'current' poll so we need to catch that error\n  current_poll <- tryCatch({\n    html %>%\n      html_nodes(\"#current-poll\") %>%\n      html_table() %>% \n      pluck(1) %>% \n      clean_names() %>% \n      mutate(chng = as.numeric(chng),\n             year = year)\n  }, error = function(e) {NULL})\n    \n  # for season-long polls\n  all_polls <- html %>%\n    html_nodes(\"#coaches-polls\") %>%\n    html_table() %>% \n    pluck(1) %>% \n    row_to_names(2) %>% \n    clean_names() %>% \n    rename_with(~paste0(\"week_\", seq_along(.)), starts_with(\"x\")) %>% # shift to week_X name format\n    mutate(across(-c(school, conf), as.numeric),\n           year = year)\n  \n  return(list(\"current\" = current_poll, \"all\" = all_polls))\n\n}\n```\n:::\n\n\n## Looping\n\nTo grab data over multiple seasons, we will utilize the `purrr` package to \"map\" a vector of seasons to our function. As an example, we will grab all polling data from 2010-2024.\n\nSince our functions return nested lists, and not a single data frame, we will use `purrr::map` and then combine the rows of *just* elements named \"all\" using `lapply`. In practice, it might be easier to alter the scraping functions to only return a single data frame (the \"all\" frame) and use `purrr::map_dfr`.\n\n### AP Poll\n\n\n::: {.cell}\n\n```{.r .cell-code}\nap_polling_data <- map(2010:2024, \\(year) get_ap_poll(year), .progress = 'Scraping')\n\nap_polling_data <- bind_rows(lapply(ap_polling_data, `[[`, \"all\"))\n```\n:::\n\n\nFor plotting purposes, it might be preferred to pivot your data to a \"long\" format, and we can do that using `tidyr::pivot_longer`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nap_pivot <- ap_polling_data %>% \n  pivot_longer(-c(school, conf, year), names_to = \"week\", values_to = \"rank\")\n```\n:::\n\n\n### Coaches Poll\n\nThe process is the same as above, just switch to using the `get_coaches_poll` function.\n\n## Cleaning\n\nThere is not much cleaning to do with this data. I do want to highlight the `cbbdata::cbd_match_teams` function, which will convert all team names to conventions found in `cbbdata`. The `cbbplotR` package, however, does not require this, and unless you are combining your polling data with `cbbdata` functions, there is no clear reason to convert the names. But if you wish to do so:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmatches <- cbbdata::cbd_match_teams()\n\nap_pivot %>% \n  mutate(school = matches[school])\n```\n:::\n\n\n## Data Glimpse\n\n| school | conf | year | week   | rank |\n|:-------|:-----|-----:|:-------|-----:|\n| Duke   | ACC  | 2010 | pre    |    9 |\n| Duke   | ACC  | 2010 | week_1 |    9 |\n| Duke   | ACC  | 2010 | week_2 |    7 |\n| Duke   | ACC  | 2010 | week_3 |    6 |\n| Duke   | ACC  | 2010 | week_4 |    8 |\n| Duke   | ACC  | 2010 | week_5 |    7 |\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}